{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "\n",
    "- Quick recap\n",
    "- Python data structures\n",
    "- Pandas\n",
    "- Importing data\n",
    "    - Flat files\n",
    "    - JavaScript Object Notation (JSON)\n",
    "    - API\n",
    "    - Working with relational databases in Python    \n",
    "- Importing data from statistical software packages\n",
    "- Cleaning data\n",
    "    - Exploring your data\n",
    "    - Cleaning data for analysis\n",
    "- Q&A\n",
    "    \n",
    "    \n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data\n",
    "\n",
    "- Prepare data for analysis\n",
    "\n",
    "- Data almost never comes in clean\n",
    "\n",
    "- Diagnose your data for problems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common data problems\n",
    "\n",
    "- Inconsistent column names Missing data\n",
    "- Outliers\n",
    "- Duplicate rows\n",
    "- Untidy\n",
    "- Need to process columns\n",
    "- Column types can signal unexpected data values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import NaN\n",
    "import re\n",
    "#https://docs.python.org/3/library/re.html\n",
    "\n",
    "import seaborn as sns\n",
    "#https://seaborn.pydata.org/#:~:text=Seaborn%20is%20a%20Python%20data,introductory%20notes%20or%20the%20paper.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "#https://github.com/ResidentMario/missingno\n",
    "import datetime as dt\n",
    "#https://docs.python.org/3/library/datetime.html\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring your data\n",
    "\n",
    "You're going to look at a subset of the **Department of Buildings Job Application** Filings dataset from the NYC Open Data portal. This dataset consists of job applications filed on January 22, 2017.\n",
    "\n",
    "<https://data.cityofnewyork.us/Housing-Development/DOB-Job-Application-Filings/ic3t-wcy2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "#import pandas as pd\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv('data/dob_job_application_filings_subset.csv')\n",
    "\n",
    "# Print the head of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of df\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the columns of df\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency counts for categorical data\n",
    "\n",
    "As you've seen, .describe() can only be used on numeric columns. So how can you diagnose data issues when you have categorical data? One way is by using the .value_counts() method, which returns the frequency counts for each unique value in a column!\n",
    "\n",
    "This method also has an optional parameter called dropna which is True by default. What this means is if you have missing data in a column, it will not give a frequency count of them. You want to set the dropna column to False so if there are missing values in a column, it will give you the frequency counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for 'Borough'\n",
    "print(df['Borough'].value_counts(dropna=False))\n",
    "\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value_counts for 'State'\n",
    "print(df['State'].\n",
    "      value_counts(dropna=False).\n",
    "      head()\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value counts for 'Site Fill'\n",
    "print(df['Site Fill'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data types\n",
    "\n",
    "You'll see how ensuring all categorical variables in a DataFrame are of type category reduces memory usage.\n",
    "\n",
    "Tips data contains information about how much a customer tipped, whether the customer was male or female, a smoker or not, etc.\n",
    "\n",
    "Look at the output of tips.info(). You'll note that two columns that should be categorical - sex and smoker - are instead of type object, which is pandas' way of storing arbitrary strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv('data/tips.csv')\n",
    "\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sex column to type 'category'\n",
    "tips.sex = tips.sex.astype('category')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the smoker column to type 'category'\n",
    "tips.smoker = tips.smoker.astype('category')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with numeric data\n",
    "\n",
    "If you expect the data type of a column to be numeric (int or float), but instead it is of type object, this typically means that there is a non numeric value in the column, which also signifies bad data.\n",
    "\n",
    "You can use the **pd.to_numeric()** function to convert a column into a numeric data type. If the function raises an error, you can be sure that there is a bad value within the column. \n",
    "\n",
    "You can choose to ignore or coerce the value into a missing value, NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'total_bill' to a numeric dtype\n",
    "tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html\n",
    "\n",
    "# Print the info of tips\n",
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicate data\n",
    "Duplicate data causes a variety of problems. From the point of view of performance, they use up unnecessary amounts of memory and cause unneeded calculations to be performed when processing data. In addition, they can also bias any analysis results.\n",
    "\n",
    "A dataset consisting of the performance of songs on the Billboard charts has been pre-loaded into a DataFrame called billboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('data/billboard.csv')\n",
    "\n",
    "billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric data or ... ?\n",
    "\n",
    " You'll be working with bicycle ride sharing data in San Francisco called ride_sharing. It contains information on the start and end stations, the trip duration, and some user information for a bike sharing service.\n",
    " \n",
    "The user_type column contains information on whether a user is taking a free ride and takes on the following values:\n",
    "\n",
    "- 1 for free riders.\n",
    "- 2 for pay per ride.\n",
    "- 3 for monthly subscribers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_sharing = pd.read_csv(\"data/ride_sharing_new.csv\", index_col=0)\n",
    "\n",
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the information of ride_sharing\n",
    "print(ride_sharing.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics of user_type column\n",
    "print(ride_sharing['user_type'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user_type from integer to category and store it in the user_type_cat column.\n",
    "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing['user_type_cat'].dtype == 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print new summary statistics \n",
    "print(ride_sharing['user_type_cat'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing strings and concatenating numbers\n",
    "\n",
    "Another common data type problem is importing what should be numerical values as strings, as mathematical operations such as summing and multiplication lead to string concatenation, not numerical outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip duration of minutes\n",
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes') \n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/version/0.24.2/reference/api/pandas.Series.str.strip.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New column \"duration_trim\" without text\n",
    "\n",
    "ride_sharing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_sharing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print formed columns  \n",
    "ride_sharing[['duration','duration_trim','duration_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average ride duration \n",
    "\n",
    "ride_sharing['duration_time'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"data/modified_titanic_data.csv\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping unused column\n",
    "Based on our observation, there is an invalid/null Unnamed: 13 column that we do not need. We can drop it by using the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns=\"Unnamed: 13\", inplace = True)\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicate\n",
    "Let’s check for duplicates in this dataset by using this function.\n",
    "\n",
    "\n",
    "- keep allows a few parameters to check on duplicates.\n",
    "\n",
    "- first : Mark duplicates as True except for the first occurrence.\n",
    "\n",
    "- last : Mark duplicates as True except for the last occurrence.\n",
    "\n",
    "- False : Mark all duplicates as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html\n",
    "\n",
    "titanic[titanic.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have seen there are duplicates in this dataset, I would like to remove them and keep the first occurrence. The following function is used to keep the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = titanic.drop_duplicates(keep=\"first\")\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the duplicates are removed, it will return null if the duplicates are removed.\n",
    "\n",
    "titanic[titanic.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = pd.read_csv(\"data/airlines_final.csv\", index_col=0)\n",
    "\n",
    "airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines['cleanliness'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of survey columns in airlines\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of survey columns in airlines\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = pd.read_csv(\"data/categories.csv\")\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistent categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines['dest_region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.unique.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower dest_region column\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.lower.html\n",
    "\n",
    "airlines['dest_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html\n",
    "\n",
    "print(airlines['dest_region'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# https://www.w3resource.com/pandas/series/series-str-strip.php\n",
    "\n",
    "print(airlines['dest_size'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking = pd.read_csv(\"data/banking_dirty.csv\", index_col=0)\n",
    "\n",
    "banking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the header of account_opened\n",
    "print(banking['account_opened'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce') \n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "\n",
    "banking['account_opened']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce')  \n",
    "\n",
    "# Get year of account opened\n",
    "banking['acct_year'] = banking['account_opened'].dt.strftime('%Y')\n",
    "\n",
    "# Print acct_year\n",
    "print(banking['acct_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets from CSV files\n",
    "\n",
    "- CSV file has no column headers\n",
    "\n",
    "- Missing values\n",
    "\n",
    "- <http://www.sidc.be/silso/home>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'data/ISSN_D_tot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = pd.read_csv(filepath)\n",
    "\n",
    "#sunspots = pd.read_csv(\"data/ISSN_D_tot.csv\")\n",
    "\n",
    "sunspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting\n",
    "sunspots.iloc[10:20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using header keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = pd.read_csv(filepath, header=None)\n",
    "\n",
    "sunspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting\n",
    "\n",
    "sunspots.iloc[10:20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using names keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['year', 'month', 'day', 'dec_date', 'sunspots', 'definite']\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = pd.read_csv(filepath, header=None, names=col_names)\n",
    "\n",
    "sunspots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN under a single DataFrame column:\n",
    "\n",
    "sunspots['sunspots'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the NaN under a single DataFrame column:\n",
    "\n",
    "sunspots['sunspots'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using na_values keyword\n",
    "\n",
    "- read_csv() \n",
    "    - <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = pd.read_csv(filepath, header=None,\n",
    "    ...: names=col_names, na_values={'sunspots':[' -1']})\n",
    "\n",
    "sunspots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using parse_dates keyword\n",
    "\n",
    "- read_csv() \n",
    "    - <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots = pd.read_csv(filepath, \n",
    "                       header=None,\n",
    "                        names=col_names, na_values={'sunspots':[' -1']},\n",
    "                        parse_dates=[[0, 1, 2]])\n",
    "\n",
    "sunspots.iloc[10:20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files\n",
    "\n",
    "- to_csv()\n",
    "\n",
    "    - <https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunspots.to_csv(\"data/ISSN_D_tot_CLEAN_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosing data cleaning problems using simple pandas and visualizations\n",
    "\n",
    "Some important and common methods needed to get a better understanding of DataFrames and diagnose potential data problems are the following:\n",
    "\n",
    "- .head() prints the header of a DataFrame\n",
    "- .dtypes prints datatypes of all columns in a DataFrame\n",
    "- .info() provides a bird's eye view of column data types and missing values in a DataFrame\n",
    "- .describe() returns a distribution of numeric columns in your DataFrame\n",
    "- .isna().sum() allows us to break down the number of missing values per column in our DataFrame\n",
    "- .unique() finds the number of unique values in a DataFrame column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "\n",
    "This dataset contains data on airbnb listings in the state of New York. It contains the following columns:\n",
    "\n",
    "- listing_id: The unique identifier for a listing\n",
    "- description: The description used on the listing\n",
    "- host_id: Unique identifier for a host\n",
    "- host_name: Name of host\n",
    "- neighbourhood_full: Name of boroughs and neighbourhoods\n",
    "- coordinates: Coordinates of listing (latitude, longitude)\n",
    "- Listing added: Date of added listing\n",
    "- room_type: Type of room\n",
    "- rating: Rating from 0 to 5.\n",
    "- price: Price per night for listing\n",
    "- number_of_reviews: Amount of reviews received\n",
    "- last_review: Date of last review\n",
    "- reviews_per_month: Number of reviews per month\n",
    "- availability_365: Number of days available per year\n",
    "- Number of stays: Total number of stays thus far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "#airbnb = pd.read_csv('https://github.com/adelnehme/python-for-spreadsheet-users-webinar/blob/master/datasets/airbnb.csv?raw=true', index_col = 'Unnamed: 0')\n",
    "#airbnb.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "airbnb = pd.read_csv('https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V4/main/data/airbnb.csv?raw=true', index_col = 'Unnamed: 0')\n",
    "\n",
    "airbnb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By merely looking at the data, we can already diagnose a range of potential problems down the line such as:\n",
    "\n",
    "\n",
    "\n",
    "Data type problems:\n",
    "\n",
    "- **Problem 1**: We can see that the coordinates column is probably a string (str) - most mapping functions require a latitude input, and longitude input, so it's best to split this column into two and convert the values to float.\n",
    "- **Problem 2**: Similar to coordinates - the price column also is a string with $ attached to each price point, we need to convert that to float if we want a good understanding of the dataset.\n",
    "- **Problem 3**: We need to make sure date columns (last_review and listing_added) are in datetime to allow easier manipulation of data data.\n",
    "\n",
    "\n",
    "Missing data problems:\n",
    "\n",
    "- **Problem 4**: We can see that there are missing data in some columns, we'll get a better bird's eye view of that down the line.\n",
    "\n",
    "\n",
    "Text/categorical data problems:\n",
    "\n",
    "- **Problem 5**: To be able to visualize number of listings by boroughs - we need to separate neighborhoud name from borough name in neighbourhood_full column.\n",
    "- **Problem 6**: Looking at room_type, let's replace those values to make them 'Shared Room', 'Private Home/Apartment', 'Private Room' and 'Hotel Room'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print data types of DataFrame\n",
    "#airbnb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print description of DataFrame\n",
    "airbnb.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of missing values\n",
    "airbnb.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of unique values in room_type column\n",
    "airbnb['room_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many values of different room_types do we have?\n",
    "airbnb['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of the DataFrame\n",
    "airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Replace coordinates with latitude and longitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"(\" and \")\" from coordinates\n",
    "airbnb['coordinates'] = airbnb['coordinates'].str.replace(\"(\",\"\")\n",
    "airbnb['coordinates'] = airbnb['coordinates'].str.replace(\")\",\"\")\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html\n",
    "\n",
    "# Print the header of the column\n",
    "airbnb['coordinates'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split column into two\n",
    "lat_long = airbnb['coordinates'].str.split(\",\", expand = True)\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html\n",
    "\n",
    "lat_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign correct columns to latitude and longitude columns in airbnb\n",
    "airbnb['latitude'] = lat_long[0]\n",
    "airbnb['longitude'] = lat_long[1]\n",
    "\n",
    "# Print the header and confirm new column creation\n",
    "#airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out dtypes again\n",
    "airbnb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert latitude and longitude to float\n",
    "airbnb['latitude'] = airbnb['latitude'].astype('float')\n",
    "airbnb['longitude'] = airbnb['longitude'].astype('float')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html\n",
    "\n",
    "# Print dtypes again\n",
    "airbnb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop coordinates column\n",
    "airbnb.drop('coordinates', axis = 1, inplace = True)\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove $ from price and convert it to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove $ from price before conversion to float\n",
    "airbnb['price'] = airbnb['price'].str.strip(\"$\")\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.str.strip.html\n",
    "    \n",
    "# Print header to make sure change was done\n",
    "airbnb['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert price to float\n",
    "airbnb['price'] = airbnb['price'].astype('float')\n",
    "\n",
    "# Calculate mean of price after conversion\n",
    "airbnb['price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert listing_added and last_review columns to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print header of two columns\n",
    "airbnb[['listing_added', 'last_review']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both columns to datetime\n",
    "airbnb['listing_added'] = pd.to_datetime(airbnb['listing_added'], format = '%Y-%m-%d')\n",
    "airbnb['last_review'] = pd.to_datetime(airbnb['last_review'], format = '%Y-%m-%d')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print header and datatypes of both columns again\n",
    "airbnb[['listing_added', 'last_review']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print header and datatypes of both columns again\n",
    "\n",
    "airbnb[['listing_added', 'last_review']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do we have consistent date data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing some sanity checks on date data\n",
    "today = dt.date.today()\n",
    "\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there reviews in the future?\n",
    "airbnb[airbnb['last_review'].dt.date > today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there listings in the future?\n",
    "airbnb[airbnb['listing_added'].dt.date > today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any listings with listing_added > last_review\n",
    "inconsistent_dates = airbnb[airbnb['listing_added'].dt.date > airbnb['last_review'].dt.date]\n",
    "inconsistent_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these rows since they are only 2 rows\n",
    "airbnb.drop(inconsistent_dates.index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text and categorical data problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print unique values of `room_type`\n",
    "print(airbnb['room_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with capitalized values\n",
    "airbnb['room_type'] = airbnb['room_type'].str.lower()\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html\n",
    "\n",
    "print(airbnb['room_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with trailing spaces\n",
    "airbnb['room_type'] = airbnb['room_type'].str.strip()\n",
    "\n",
    "print(airbnb['room_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values to 'Shared room', 'Entire place', 'Private room' and 'Hotel room' (if applicable).\n",
    "mappings = {'private room': 'Private Room', \n",
    "            'private': 'Private Room',\n",
    "            'entire home/apt': 'Entire place',\n",
    "            'shared room': 'Shared room',\n",
    "            'home': 'Entire place'}\n",
    "\n",
    "# Replace values and collapse data\n",
    "airbnb['room_type'] = airbnb['room_type'].replace(mappings)\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html\n",
    "\n",
    "print(airbnb['room_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Divide neighbourhood_full into 2 columns and making sure they are clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print header of column\n",
    "airbnb['neighbourhood_full'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split neighbourhood_full\n",
    "borough_neighbourhood = airbnb['neighbourhood_full'].str.split(\",\", expand = True)\n",
    "\n",
    "borough_neighbourhood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create borough and neighbourhood columns\n",
    "airbnb['borough'] = borough_neighbourhood[0]\n",
    "airbnb['neighbourhood'] = borough_neighbourhood[1]\n",
    "\n",
    "# Print header of columns\n",
    "airbnb[['neighbourhood_full', 'borough', 'neighbourhood']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop neighbourhood_full column\n",
    "airbnb.drop('neighbourhood_full', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out unique values of borough and neighbourhood\n",
    "print(airbnb['borough'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out unique values of borough and neighbourhood\n",
    "\n",
    "print(airbnb['neighbourhood'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip white space from neighbourhood column\n",
    "airbnb['neighbourhood'] = airbnb['neighbourhood'].str.strip()\n",
    "\n",
    "# Print unique values again\n",
    "print(airbnb['neighbourhood'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure we set the correct maximum for rating column out of range values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate rows of rating > 5.0\n",
    "airbnb[airbnb['rating'] > 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these rows and make sure we have effected changes\n",
    "airbnb.drop(airbnb[airbnb['rating'] > 5.0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the rating column again\n",
    "sns.distplot(airbnb['rating'], bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum\n",
    "airbnb['rating'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the missingness \n",
    "msno.matrix(airbnb)\n",
    "\n",
    "# https://github.com/ResidentMario/missingno\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness barplot\n",
    "msno.bar(airbnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's deal with duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the header of the DataFrame again\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "duplicates = airbnb.duplicated(subset = 'listing_id', keep = False)\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html\n",
    "\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicates\n",
    "airbnb[duplicates].sort_values('listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove identical duplicates\n",
    "airbnb = airbnb.drop_duplicates()\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find non-identical duplicates\n",
    "duplicates = airbnb.duplicated(subset = 'listing_id', keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all duplicates\n",
    "airbnb[duplicates].sort_values('listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "329.575px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
